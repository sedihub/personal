{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0982d36-294b-4b1e-b5e6-df721bd00a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2f816-3272-4226-a99c-0536e4a07424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import socks\n",
    "# import socket\n",
    "# import ssl\n",
    "# from urllib.request import Request, urlopen\n",
    "\n",
    "# IP_ADDR = '66.97.37.164'\n",
    "# PORT = 80\n",
    "\n",
    "# n = 108\n",
    "# url = f'https://journals.aps.org/prb/issues/{n}#v{n}'\n",
    "\n",
    "# ctx = ssl.create_default_context()\n",
    "# ctx.check_hostname = False\n",
    "# ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# request = Request(url)\n",
    "# socks.set_default_proxy(socks.SOCKS5, IP_ADDR, PORT)\n",
    "# socket.socket = socks.socksocket\n",
    "# response = urlopen(request, context=ctx)\n",
    "\n",
    "# print(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10675c8f-693c-4e69-8658-6c57a084d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# proxy_support = urllib.request.ProxyHandler({\n",
    "#     'http' : 'http://66.97.37.164:80', \n",
    "#     'https': 'https://66.97.37.164:80'\n",
    "# })\n",
    "# opener = urllib.request.build_opener(proxy_support)\n",
    "# urllib.request.install_opener(opener)\n",
    "# with urllib.request.urlopen(url) as response:\n",
    "#     contents = response.read()\n",
    "# print(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bbe191-13ec-4102-be63-baed7e8526da",
   "metadata": {},
   "source": [
    "# Crawl APS PRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b27b8dd-b70b-49a9-a70d-1896d23563ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATEST_VOL_NUMBER = 108\n",
    "# PROXY_HOST = \"http://47.91.88.100:8080\"  #\"http://81.171.24.199\"  # \"http://91.211.245.176\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddc0a203-ebbf-4c6e-95b7-106661c6f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_contents(url, proxy_host=None):\n",
    "    if proxy_host is None or proxy_host == '':\n",
    "        response = urllib.request.urlopen(url)\n",
    "    else:\n",
    "        req = urllib.request.Request(url)\n",
    "        req.set_proxy(proxy_host, 'http')\n",
    "        response = urllib.request.urlopen(req)\n",
    "    return response.read().decode(\"utf-8\")\n",
    "\n",
    "def get_abstract_urls(page_text):\n",
    "    \"\"\"Extracts URLs for page text.\n",
    "    \"\"\"\n",
    "    urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', page_text)\n",
    "    urls = list(filter(lambda x: x.find(\"/prb/abstract\") != -1, urls))\n",
    "    urls = list(filter(lambda x: x.find(\"#fulltext\") == -1, urls))\n",
    "    return ['https://journals.aps.org' + u for u in urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c27f11f-a39c-4aea-9497-62ef44c0a5c6",
   "metadata": {},
   "source": [
    "## Extract Issue URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66785362-96cc-49fa-ac76-4bfba8dfaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vol_issue = {}\n",
    "# for n in range(1, 1 + LATEST_VOL_NUMBER):\n",
    "#     vol_url = f'https://journals.aps.org/prb/issues/{n}#v{n}'\n",
    "#     page_text = get_page_contents(vol_url, proxy_host=PROXY_HOST)\n",
    "#     partial_urls = re.findall(f'\\/prb\\/issues/{n}/[0-9]+', page_text)\n",
    "#     vol_issue[n] = ['https://journals.aps.org/' + u for u in partial_urls]\n",
    "#     print(f'\\tVolume {n:>3} has {len(vol_issue[n]):>4} issues.', end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc0871-16b9-4616-84c1-8b2331b1c019",
   "metadata": {},
   "source": [
    "## Get Abstracts URLs from each Issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc725c2d-434b-485f-83b8-d064102ee20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of abstracts: 216964\n",
      "CPU times: user 48.6 ms, sys: 10.1 ms, total: 58.8 ms\n",
      "Wall time: 64.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "abstract_urls_dict = {}\n",
    "count_abstracts = 0\n",
    "try:\n",
    "    with open(\"aps_prb_abstract_urls.json\", \"r\") as file:\n",
    "      abstract_urls_dict = json.load(file)\n",
    "except:\n",
    "    for vol_num in range(1, 1 + 108):\n",
    "        abstract_urls_dict[vol_num] = {}\n",
    "        for issue_url in vol_issue[vol_num]:\n",
    "            issue_num = int(issue_url.split('/')[-1])\n",
    "            print(f'\\tVolume {vol_num:>3}, Issue {issue_num:>3}', end='\\r')\n",
    "            abstract_urls_dict[vol_num][issue_num] = get_abstract_urls(\n",
    "              get_page_contents(issue_url, proxy_host=PROXY_HOST))\n",
    "            count_abstracts += len(abstract_urls_dict[vol_num][issue_num])\n",
    "    with open(\"aps_prb_abstract_urls.json\", \"w\") as file:\n",
    "        json.dump(abstract_urls_dict, file, indent=4)\n",
    "else:\n",
    "    for vol_num, issue_dict in abstract_urls_dict.items():\n",
    "        for issue_num, abstract_urls in issue_dict.items():\n",
    "            count_abstracts += len(abstract_urls)\n",
    "\n",
    "print(f'\\nTotal number of abstracts: {count_abstracts}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cc1ca8-affe-4477-a45a-990fbddb76d5",
   "metadata": {},
   "source": [
    "## Extract Abstract Metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad9d77e-f534-447c-b769-74355a376a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_abstract(abstract_url):\n",
    "    \"\"\"Extracts metadata from abstracts:\n",
    "    \"\"\"\n",
    "    abstract_page_content = get_page_contents(abstract_url)\n",
    "\n",
    "    # Title:\n",
    "    title = re.findall(r'\\\"citation\\_title\\\" content\\=\\\"(.*)\\\"\\/\\>', abstract_page_content)\n",
    "    if len(title) == 0 or len(title) > 1:\n",
    "        raise ValueError(f\"More than one title was found!\\n{title}\")\n",
    "    else:\n",
    "        title = title[0]\n",
    "    \n",
    "    # Published Date:\n",
    "    published_date = re.findall(r'Published\\s+(\\d{1,2}) (\\w+) (\\d{4})', abstract_page_content)\n",
    "    if len(published_date) == 0:\n",
    "        raise ValueError(\"No published date!\")\n",
    "    elif len(published_date) > 1:\n",
    "        raise ValueError(f\"More than one published date!\\n{published_date}\")\n",
    "    else:\n",
    "        published_date = published_date[0]\n",
    "        published_date = ' '.join(published_date)\n",
    "\n",
    "    # Citations:\n",
    "    citing_articles = re.findall(r'Citing Articles \\(([0-9]+)\\)', abstract_page_content)\n",
    "    citing_articles = list(set(citing_articles))\n",
    "    if len(citing_articles) == 0:\n",
    "        citing_articles = 0\n",
    "    elif len(citing_articles) == 1:\n",
    "        citing_articles = int(citing_articles[0])\n",
    "    elif len(citing_articles) > 1:\n",
    "        raise ValueError(f\"More than one unique reference to \\\"Citing Articles\\\"!\\n{citing_articles}\")\n",
    "\n",
    "    # Authors:\n",
    "    authors = re.findall(r'\\\"citation\\_author\\\" content\\=\\\"(.*)\\\"\\/\\>', abstract_page_content)\n",
    "\n",
    "    return {\n",
    "        \"Title\": title,\n",
    "        \"Published Date\": published_date, \n",
    "        \"Number of Citations\": citing_articles,\n",
    "        \"Authors\": authors, \n",
    "        \"Contents\": abstract_page_content\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20dd6e07-aea4-4426-b825-9c849bba6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test:\n",
    "# get_data_from_abstract(abstract_urls_dict[\"107\"][\"1\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61840837-4994-4b2c-89ab-8a4e74b83bbf",
   "metadata": {},
   "source": [
    "### Get abstract metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7f383f7-fb00-4db3-a3de-f124a757252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tVol.   2 Iss.   7 https://journals.aps.org/prb/abstract/10.1103/PhysRevB.2.2819.2                                                                 \r"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m abs_url \u001b[38;5;129;01min\u001b[39;00m abstract_urls:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mVol. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvol_num\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Iss. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00missue_num\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mabs_url\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<128\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     temp_dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_from_abstract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     temp_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m vol_num\n\u001b[1;32m     11\u001b[0m     temp_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIssue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m issue_num\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mget_data_from_abstract\u001b[0;34m(abstract_url)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data_from_abstract\u001b[39m(abstract_url):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extracts metadata from abstracts:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     abstract_page_content \u001b[38;5;241m=\u001b[39m \u001b[43mget_page_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstract_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Title:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     title \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcitation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m_title\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m content\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.*)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m, abstract_page_content)\n",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m, in \u001b[0;36mget_page_contents\u001b[0;34m(url, proxy_host)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_page_contents\u001b[39m(url, proxy_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proxy_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m proxy_host \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         req \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url)\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "VOL_DELAY = 900.0\n",
    "DELAY = 1.0\n",
    "\n",
    "for vol_num, issue_dict in abstract_urls_dict.items():\n",
    "    abstract_data = []\n",
    "    for issue_num, abstract_urls in issue_dict.items():\n",
    "        for abs_url in abstract_urls:\n",
    "            print(f\"\\tVol. {vol_num:>3} Iss. {issue_num:>3} {abs_url:<128}\", end=\"\\r\")\n",
    "            temp_dict = get_data_from_abstract(abs_url)\n",
    "            temp_dict['Volume'] = vol_num\n",
    "            temp_dict['Issue'] = issue_num\n",
    "            temp_dict['Abstract URL'] = abs_url\n",
    "            abstract_data.append(temp_dict)\n",
    "            time.sleep(DELAY)\n",
    "    df = pd.DataFrame(abstract_data)\n",
    "    df.to_csv(f\"abstracts/vol_{vol_num}.csv\", index=False)\n",
    "    time.sleep(VOL_DELAY)\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff785ac-d8c9-4911-8991-1aa738a664a6",
   "metadata": {},
   "source": [
    "### Multi-threaded extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56545d75-63f8-4479-a3d8-ea35b1ec85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading\n",
    "# import random\n",
    "# import time\n",
    "\n",
    "# def global_issue_count(vol_issue):\n",
    "#     \"\"\"Given a tuple of (vol, iss.), returns the \n",
    "#     issue number accross all volumes.\n",
    "#     \"\"\"\n",
    "#     vol_issue_count = {}\n",
    "#     counter = 1\n",
    "#     for vol_num, issues in vol_issue.items():\n",
    "#         for issue_url in issues:\n",
    "#             issue_num = int(issue_url.split('/')[-1])\n",
    "#             vol_issue_count[(vol_num, issue_num)] = counter\n",
    "#             counter += 1 \n",
    "#     return vol_issue_count\n",
    "\n",
    "# def threaded_extractor(thread_idx, num_threads, abstract_urls_dict, vol_issue_count):\n",
    "#     global abstract_data_dict\n",
    "#     for vol_num, issue_dict in abstract_urls_dict.items():\n",
    "#         for issue_num, abstract_urls in issue_dict.items():\n",
    "#             if vol_issue_count[(vol_num, issue_num)] % num_threads != thread_idx:\n",
    "#                 continue\n",
    "#             for abs_num, abs_url in enumerate(abstract_urls, start=1):\n",
    "#                 print(f\"\\t[{thread_idx:^3}] Vol. {vol_num:^3} Iss. {issue_num:^3} {abs_url:<128}\", end=\"\\r\")\n",
    "#                 temp_dict = get_data_from_abstract(abs_url, proxy_host=PROXY_HOST))\n",
    "#                 temp_dict['Volume'] = vol_num\n",
    "#                 temp_dict['Issue'] = issue_num\n",
    "#                 temp_dict['Abstract URL'] = abs_url\n",
    "#                 abstract_data_dict[thread_idx].append(temp_dict)\n",
    "    \n",
    "#                 # sleep_ms = random.randint(100, 500)\n",
    "#                 # time.sleep(0.001 * sleep_ms)\n",
    "  \n",
    "#             # if len(abstract_data_dict[thread_idx]) >= 10:\n",
    "#             #     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2177f83-0446-40cb-a981-8eda729b3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_threads = 10\n",
    "# threads = []\n",
    "# abstract_data_dict = {}\n",
    "# vol_issue_count = global_issue_count(vol_issue)\n",
    "# for t_idx in range(num_threads):\n",
    "#     abstract_data_dict[t_idx] = []\n",
    "#     threads.append(\n",
    "#         threading.Thread(\n",
    "#             target=threaded_extractor, \n",
    "#             args=(t_idx, num_threads, abstract_urls_dict, vol_issue_count))\n",
    "#     )\n",
    "\n",
    "# for t_idx in range(num_threads):\n",
    "#     threads[t_idx].start()\n",
    "\n",
    "# for t_idx in range(num_threads):\n",
    "#     threads[t_idx].join()\n",
    "\n",
    "# abstract_data = []\n",
    "# for key, val in abstract_data_dict.items():\n",
    "#     abstract_data.extend(val)\n",
    "# print(f\"\\nNumber of records: {len(abstract_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81015b-2072-48cf-baf7-5c62964d1f3d",
   "metadata": {},
   "source": [
    "## Convert to Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a522db-e695-4641-9eb9-631330f1ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(abstract_data)\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09a75f-244a-4725-810e-3d0e85b59e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export DataFrame to CSV:\n",
    "# df.to_csv(\"aps_prb_articles_meta_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
